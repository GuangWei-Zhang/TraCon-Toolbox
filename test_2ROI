#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu Aug 22 14:14:39 2019

@author: zhangguangwei
"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Fri Feb  1 15:23:57 2019

@author: zhangguangwei
"""
from datetime import datetime
import time
import cv2
import numpy as np
#import matplotlib.pyplot as plt
import os
from math import hypot
from tkinter import Tk
import serial
from operator import sub  # this is for tuple calculation
#arduinoData =[]
#serial.Serial('/dev/cu.usbmodem14101',9600)

#def led_on():
    #arduinoData.write(str.encode('1'))
    
#def led_off():
    #arduinoData.write(str.encode('0'))

starttime = datetime.now()
deltaseconds = datetime.now()-starttime
deltaminutes = int(deltaseconds.total_seconds()/60) 
    
dateT = str(datetime.now().year) + str(datetime.now().month)+str(datetime.now().day) + '_'+str(datetime.now().hour)+'_'+ str(datetime.now().minute)
    


cap = cv2.VideoCapture(0)

root = '/Users/zhangguangwei/Dropbox/LPO_VGAT_RTPP/'

font = cv2.FONT_HERSHEY_SIMPLEX


Moving_track = [(0,0)]

width = int(cap.get(3))
height = int(cap.get(4))

fourcc = cv2.VideoWriter_fourcc('m','p','4','v')

################ 改名字以后记得保存 
out = cv2.VideoWriter(root+'testing.mp4',fourcc,30,(width,height))
##################




Peak_speed = 0


while not cap.isOpened():
    cap = cv2.VideoCapture(0)
    #ret, img_raw =cap.read()
    
    #img_gray = cv2.cvtColor(img_raw,cv2.COLOR_BGR2GRAY)
    #r = cv2.selectROI(img_gray)
    
    cv2.waitKey(1000)
    #os.system('play --no-show-progress --null --channels 1 synth %s sine %f' % (duration, freq))
    print("Can't load the file")
    break
# pos_frame = cap.get(cv2.cv.CV_CAP_PROP_POS_FRAMES)

a=[(0,0)]
i=0
Counting = 0
record = False




    
    



while deltaminutes < 21:
    deltaseconds = datetime.now()-starttime
    deltaminutes = int(deltaseconds.total_seconds()/60) 
    i+=1
    ret, img_raw =cap.read() #start capture images from webcam
    
    if i ==1:
        cap = cv2.VideoCapture(0)
        ret, img_raw =cap.read()
        img_gray = cv2.cvtColor(img_raw,cv2.COLOR_BGR2GRAY)
        r = cv2.selectROI(img_gray)
        
        cap = cv2.VideoCapture(0)
        ret, img_raw =cap.read()
        img_gray = cv2.cvtColor(img_raw,cv2.COLOR_BGR2GRAY)
        r2 = cv2.selectROI(img_gray)

    if ret == False:
        break
    img_raw1 = img_raw[int(r[1]):int(r[1]+r[3]),int(r[0]):int(r[0]+r[2])]
    
    img_raw2 = img_raw[int(r2[1]):int(r2[1]+r2[3]),int(r2[0]):int(r2[0]+r2[2])]
    
    
    #cv2.imshow('img_raw1',img_raw1)
    #cv2.imshow('img_raw2',img_raw2)
    
    #out.write(img_raw)
    img_gray_1 = cv2.cvtColor(img_raw1,cv2.COLOR_BGR2GRAY)
    img_gray_2 = cv2.cvtColor(img_raw2,cv2.COLOR_BGR2GRAY)
    
    pt_1_1 = (int(r[0]),int(r[1])) 
    pt_1_2 = (int(r[0]+r[2]),int(r[1]+r[3]))
    
    bounding_box_1_height = int(r[3])
    bounding_box_1_width = int(r[2])
    
    
    
    #print('pt_1_1:',pt_1_1)
    #print('pt_1_2:',pt_1_2)
    
    
    pt_2_1 = (int(r2[0]),int(r2[1]))
    pt_2_2 = (int(r2[0]+r2[2]),int(r2[1]+r2[3]))
    
    bounding_box_2_height = int(r2[3])
    bounding_box_2_width = int(r2[2])
    
    cv2.rectangle(img_raw,pt_1_1,pt_1_2,[255,255,255],2)
    cv2.rectangle(img_raw,pt_2_1,pt_2_2,[0,255,255],2)
    
    
    
    
  

    blur_1 = cv2.GaussianBlur(img_gray_1,(5,5),0)
    blur_2 = cv2.GaussianBlur(img_gray_2,(5,5),0)
    
    

    retval_1,img_bi_1 = cv2.threshold(blur_1,50,255,cv2.THRESH_BINARY_INV)
    retval_2,img_bi_2 = cv2.threshold(blur_2,50,255,cv2.THRESH_BINARY_INV)
    
    binary_1,contours_1,hierarchy_1 = cv2.findContours(img_bi_1.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)
    binary_2,contours_2,hierarchy_2 = cv2.findContours(img_bi_2.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)

    if len(contours_1) > 0:
        c_1 = max(contours_1, key=cv2.contourArea)
            #((x, y), radius) = cv2.minEnclosingCircle(c)
        M_1 = cv2.moments(c_1)
        center_1 = (int((M_1["m10"] / M_1["m00"])), int((M_1["m01"] / M_1["m00"])))
        cv2.circle(img_raw, tuple(map(sum, zip(center_1, pt_1_1))), 5, (0, 0, 255), -1)
        
        #cv2.circle(img_raw, tuple(map(sum, zip(center_1, pt_1_1))), 250, (0, 0, 255), 1)
        
        trigger_region_ul = (center_1[0]- 40 + int(r[0]), int(r2[1]))
        trigger_region_lr = (center_1[0]+ 40 + int(r[0]), int(r2[1]+r2[3]))
        
        cv2.circle(img_raw, trigger_region_ul, 5, (0, 100, 150), -1)
        
        cv2.rectangle(img_raw,trigger_region_ul,trigger_region_lr,[0,255,255],2)
        
        
    if len(contours_2) > 0:
        c_2 = max(contours_2, key=cv2.contourArea)
        #((x, y), radius) = cv2.minEnclosingCircle(c)
        M_2 = cv2.moments(c_2)
        center_2 = (int((M_2["m10"] / M_2["m00"])), int((M_2["m01"] / M_2["m00"])))
        cv2.circle(img_raw, tuple(map(sum, zip(center_2, pt_2_1))), 5, (0, 0, 255), -1)
        
    
    
    Counting_1 = int(center_2[0])+int(r2[0]) >  (center_1[0]- 40 + int(r[0])); 
    Counting_2 = int(center_2[0])+int(r2[0]) < center_1[0]+ 40 + int(r[0]);
    
    if Counting_1 & Counting_2:
        led_on()        
    else
        led_off()
        
        #if Counting_temp:
                 #   led_on()
                #else:
                 #   led_off()
    
    
    
    
        #cv2.drawContours(img_raw,contours_2+[200,100],-1,(0,255,0),-1)
    
    cv2.imshow('raw',img_raw)
    out.write(img_raw)
  #print(np.mean(contours))

  # only proceed if at least one contour was found
    #if len(contours) > 0:
		# find the largest contour in the mask, then use
		# it to compute the minimum enclosing circle and
		# centroid
       # c = max(contours, key=cv2.contourArea)
       # ((x, y), radius) = cv2.minEnclosingCircle(c)
       # try:
         #   M = cv2.moments(c)
         #   center = ((M["m10"] / M["m00"])+(y_start), (M["m01"] / M["m00"])+(x_start))

          #  if radius >10:
                #cv2.circle(img_raw, (int(x), int(y)), int(radius), (0, 255, 255), 2)
                #cv2.circle(img_raw, center, 5, (0, 0, 255), -1)

                #print('Moving_track:',Moving_track[-1][0],'Center:',center[0])
                #d_dist = hypot(Moving_track[-1][0]-center[0],Moving_track[-1][1]-center[1])
                #Speed = (d_dist/0.04)*0.075
                #print('Delta_dist:', d_dist)
                #d_dist =round(d_dist,2)
                #temp = "{:0>.2f}".format(Speed)
                
                
                #cv2.putText(img_raw,'Speed: '+temp,(50,50),font,1,(255,255,255),2,cv2.LINE_AA)
                #cv2.putText(img_raw,'cm/s',(280,50),font,1,(255,255,255),2,cv2.LINE_AA)

                #Peak_speed = max(Peak_speed,Speed)
                #temp2 = "{:0>.2f}".format(Peak_speed)
                #cv2.putText(img_raw,'Peak speed: '+temp2,(50,80),font,1,(255,255,255),2,cv2.LINE_AA)
                #cv2.putText(img_raw,'cm/s',(380,80),font,1,(255,255,255),2,cv2.LINE_AA)

                #cv2.rectangle(img,(center[0]-45,center[1]-45),(center[0]+45,center[1]+45),[255,255,255],2)
                #cv2.imshow('img_raw',img_raw)
                #img[1:91,-91:-1] = img_raw[center[1]-45:center[1]+45,center[0]-45:center[0]+45]

                #Moving_track.append(center)
                

                #points = np.array(Moving_track)
                #cv2.polylines(img_raw,np.int32([points[1:]]),0,(0,0,255))
                
                #out.write(img_raw)
                #line = str(center[0])+','+str(center[1])+','+str(Speed)+'\n'
                
              
              #  
           #     Counting_temp = (float(center[0]) > x_start_region4Counting) & (float(center[0]) < x_stop_region4Counting)  & (float(center[1]) > y_start_region4Counting) & (float(center[1]) < y_stop_region4Counting)       
                #if Counting_temp:
                 #   led_on()
                #else:
                 #   led_off()
                        
                
                #Counting+=Counting_temp
                #print(Counting_temp)
                
                
                
                #percentage_in_region4Counting = Counting/i
                #temp_percent = "{:0>.2f}".format(percentage_in_region4Counting)
           #     cv2.putText(img_raw,str(Counting_temp),(50,50),font,1,(255,0,0),2,cv2.LINE_AA)
           #     #print(temp_percent)
          #      cv2.rectangle(img_raw,(x_start_region4Counting,y_start_region4Counting),(x_stop_region4Counting,y_stop_region4Counting),(255,0,0))
           #     cv2.imshow(r'img',img_raw)
                
                
                
                #with open(root+r'_trackTrace.csv','a') as f:
                 #   f.write(line)


       # except ZeroDivisionError:
          #  print("error")
       # 

#print("this is frame#:", i)


#cv2.imshow("img",img)



    if cv2.waitKey(1) & 0xFF == ord('q'):
        break
        
cap.release()
#print(temp_percent)
          # i+=1

      # only proceed if the radius meets a minimum size
    #if radius > 10:
      # draw the circle and centroid on the frame,
      # then update the list of tracked points
   #      cv2.circle(img, (int(x), int(y)), int(radius),
    #     (0, 255, 255), 2)
    #     cv2.circle(img, center, 5, (0, 0, 255), -1)


     #cv2.imshow("img",img)



print("Processing Done!")
led_off()
cv2.destroyAllWindows()
out.release()

